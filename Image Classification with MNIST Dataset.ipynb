{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is an overview of the basics of CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers\n",
    "Convolutional layers are used to extract features from images. Pixels are only related to adjacent and close pixels. Convolution allows the relationship between different parts of an image to be preserved by filtering an image with a smaller pixel filter to decrease the size of an image without loosing relationship between pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layers\n",
    "Pooling layers are usually inserted after each convolution layer to reduce the spataial size of the convolved representation in order to reduce the computational complexity. Pooling layer also helps with overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layers\n",
    "Similar to a MLP, fully connected layers is usually used to classify the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "print(train_data.shape)\n",
    "\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc: integer-location based indexing for selection by position.\n",
    "# train.iloc[cols, rows]\n",
    "\n",
    "# Make sure that the values are float to get decimal points after division\n",
    "X_train = (train_data.iloc[:,1:].values).astype('float32') # all pixel values\n",
    "y_train = train_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n",
    "X_test = test_data.values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEICAYAAAAjhV3sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHNlJREFUeJzt3Xe0VOXVx/HvE4pIj3QJolEURYSAgnmRABEpQSPECqKoaESKokbFhS1C1NgSFwgkSERQYsSIohCkSEQkWGJvoCYiAQQEpXfO+8d138M83At36pl77u+zlsswd+6ZTY6zZ89T9uOCIEBEREI/iDoAEZF8o8QoIuJRYhQR8Sgxioh4lBhFRDxKjCIiHiVGERFP7BKjc26wc+4t59wO59zEqOORzHDOHeacm+ac2+KcW+ac6xN1TJK+fH2/lo86gCxYCYwEugKHRhyLZM4jwE6gHtASmOGcey8Igo+iDUvSlJfv19hVjEEQPBsEwXPAuqhjkcxwzlUBzgFuC4JgcxAEC4HpwMXRRibpytf3a+wSo8TSscDuIAiW7vPYe0CziOKRmFNilNKgKrDRe2wDUC2CWKQMUGKU0mAzUN17rDqwKYJYpAxQYpTSYClQ3jnXZJ/HWgCaeJGsiF1idM6Vd85VAsoB5ZxzlZxzcZx9LzOCINgCPAvc5Zyr4pxrB5wNTI42MklXvr5fY5cYgVuBbcAwoO/3//vWSCOSTBhIwXKONcBfgau1VCcW8vL96tSoVkQkURwrRhGRtCgxioh4lBhFRDxKjCIinpxOizvnYjvTEwSBizqGqOi+xlNZvq+qGEVEPEqMIiIeJUYREY8So4iIR4lRRMSjxCgi4lFiFBHxRN7eJ1/MnTsXgNNPPx2Afv36ATBp0qTIYiqrDjvsMACqVq0KwKBBgwp/1rZtWwDGjBkDwMaNBY29X3rpJQDUFKX0KFeuHAD33Xcfe/fuBWDYsGEA7NmzJ7K4QBWjiMh+ynzFOH/+fADatWsHUPjJpcojd6pVKzi6pXv37gA88cQTAJQvX/x/ng0aNACgUaNGADz++OMA/P73vwfgyy+/zEqskjkVK1YE4Lrrrit87LbbbgNUMYqI5J2cNqrNp72Xw4cPB8JPqAoVKgDw9NNPA9C/f38Atm7dWqLraU9t8mrWrAnA5MkFJxT06NEj7VhWr14NwNlnnw3AkiVLANiwYUNK19N9zZ5DDz0UgC1bthQ+VrlyZQC2b9+ezZfWXmkRkWSVuYqxZ8+eAPz1r38FwnGODz74AID27dsDsGlTcidzqrJIXrdu3QCYOXNmRuPZ18CBAwEYN25cSr+v+5o9RVWMtgJh7Nix2XxpVYwiIskqM7PSNnt5xx13AGGluH79eiAca0y2UpTknXbaaQDcfPPNSf3etddey8qVKwH4zW9+A4TrGotz//33A7Bu3ToApk6dmtRrSm7Z2HC2K8aDUcUoIuKJfcXYpk0bAMaPHw/AiSeemPDzIUOGAPDCCy/kNrAybOjQoQB06NChyJ+/9dZbALz++usJj8+fP58PP/wQgFmzZgHhLhmrBO1+mypVqgBw/vnnJzxP5EBUMYqIeGJbMV588cVAuCPCZt9tPZvtjbY9tpJ9zhVMBP7gB0V/Hl900UUArFmzBoB58+YVey2bybR/WwV58sknF/kaTZs2BeDMM88E4MUXX0z+LyBlhipGERFPLCvGevXqceONNxb5s+effx6Ayy67LJchCXDSSScB4VpS38KFCwFYvnx50te+8847gXA9qj+W2KxZMwDOOussQBVjPrD90HPmzOGMM86IOJpEqhhFRDyxqhht7+3s2bMLKwRj6xOnT5+e87ikwFFHHVXk49ZTcdeuXWm/xqJFixKuWb169bSvKdmxc+dOACZOnKiKUUQk38WqYrQ1a/5aRQh3vmhnS3S+++67Ih9/4403APj222/Tfo1Vq1YB4f7rCy+8MOHnXbt2BcLu4Js3b077NSU11m/zpz/9acSR7C8WibF27dpAuEjbloUALF68GAjLdsk9+zr71FNPFfnzzp07A1C3bl0gtckX35NPPgnsnxiPOOIIIGwzJ9GxezB48OCII9mfvkqLiHhiUTGOHj0agBYtWgAFi7ltEN6qkR07dkQTnBR+ZbKKMBdWrFiRs9eS+FHFKCLiKdUVo40tHn300QmP79q1q/BQJFWK0bNJFxv3s61/IvlKFaOIiKdUVow2VjVlyhQAWrVqBYQH6AwYMEBbvvKIHUk7Z84coPiK0bbx2bhwKktpbJG/NQ/x2REHxS0dEgFVjCIi+ymVFWOvXr0A6NSpU8LjtlDYjuOU/GINPN59910AWrZsmfBzazL78ssvA+HRB/Pnzz/otevUqQPAAw88AEDz5s0Tfr5t2zaAwrHnXB4CJ6WPKkYREU+pqhh79+4NhJ/6xtYs9unTJ+cxSclZk+BrrrkGCA888ht+WLPZ3/72t0DiVkFrDmGHmVWqVAkIxxT9StHYFsFly5al+beQTBk1alTUIRRLFaOIiKdUVIw1atQAYMSIEQBUq1Yt4ecPPvggEDYQkPxmDWntfk6YMAEIm4AYO2b17bffLnxs7dq1AFSuXLnI3ymODsHKP9bYZd/eBvlCFaOIiKdUVIx2CHdxjU7VjLR0evrppwFo2LAhEFb+B2Kzzwdj45lXXXUVADNmzEglRMmBfFwhoIpRRMRTKipGa3lvOyjsaEw7TKdJkybRBCYZ8eijjwIUtrfv1q1bytey41QvuOACoOCYC5FkqWIUEfG4XH6/d86l9WIff/wxEPb3+93vfgcUvy82l4IgyL+ptRxJ974aW5Noe6W7dOkChB2enXOF41E2k2lr4WzN4+7du4FwjDFduq/Z06FDByBxZ1PHjh0BWLBgQTZf+qD3VRWjiIinVFWM+UyVRTzpvsaTKkYRkSQpMYqIeJQYRUQ8SowiIh4lRhERjxKjiIhHiVFExJPTdYwiIqWBKkYREY8So4iIR4lRRMSjxCgi4lFiFBHxKDGKiHiUGEVEPEqMIiIeJUYREY8So4iIR4lRRMSjxCgi4oltYnTONXHObXfOPRF1LJI+59xhzrlpzrktzrllzrk+Ucck6cvX+1o+6gCy6BHgzaiDkIx5BNgJ1ANaAjOcc+8FQfBRtGFJmvLyvsay7Zhz7kLgV8DHwDFBEPSNOCRJg3OuCvAtcGIQBEu/f2wysCIIgmGRBicpy+f7Gruv0s656sBdwPVRxyIZcyyw294833sPaBZRPJIZeXtfY5cYgRHAhCAI/hd1IJIxVYGN3mMbgGoRxCKZk7f3NVZjjM65lkBn4CdRxyIZtRmo7j1WHdgUQSySOXl7X2OVGIGOwJHAV845KPhEKuecOyEIglYRxiXpWQqUd841CYLgs+8fawFo4qV0y9v7GqvJF+dcZRI/gX5DQaK8OgiCtZEEJRnhnHsKCIArKJi9nAn8X9Szl5KefL2vsaoYgyDYCmy1PzvnNgPblRRjYSDwF2ANsI6CDzslxdIvL+9rrCpGEZFMiOOstIhIWpQYRUQ8SowiIh4lRhERT05npZ1zsZ3pCYLARR1DVHRf46ks31dVjCIiHiVGERGPEqOIiEeJUUTEo8QoIuJRYhQR8cSqiYSUbt+3iqN+/foADBw4EIAGDRoA0L9///1+57HHHgPgzjvvBOB//yvoT7x3796sxirpK1euHAD33Xcf7du3B+Dkk08G4NVXXwVg0KBBAHz44Yc5jU0Vo4iIJ6fddZJdMPr5558D8MknnwBwzjnnALBz586UYzj00EMB6Ny5MwAvvPBCytfalxYCp65SpUoA9OvXD4CxY8emfK0bbrgBgIcffhhIv3LUfc28ChUqADBx4kQAevfuzYwZMwD47rvvADj//POB8L1+3nnnATBr1qyMxKAF3iIiScrrivFHP/oRAJ99VtD1/PDDDwfg22+/TTmGhg0bAjBt2jQA2rRpk/K19qXKInlVqlQBYNGiRQA0b948YzENGTIEgEceeSSt6+i+Zt4999wDwM033wzAuHHjCseTzbx58wDo1KkTAFu2bAHgxBNPBGDZsmVpxaCKUUQkSXk9K20zjLt27QIKZq8ArrzyyrSvbbNfHTp0AOCVV15J+5qSnNq1awOZrRSNVYw2RvWXv/wFgD179mT8taRkevXqBcB1110HwAcffADAtddeu99zV65cCcD69esBOOywwwA499xzAXjwwQezGqsqRhERT16PMRqbvWrRogUAbdu2BVKbnbYxxuXLlwNw+umnAzB//vxUQiuksaiSq1evHgBz584FoFmzZkU+z74p/O1vfwMoXOsG4VrHQw45pESvefzxxwOwZMmSZELVfc0AW3Xw5ptvAuH9Pu2004BwjLkoRx55ZMJz1q1bB0Dr1q2B1FeoaIxRRCRJeT3GaP773/8CcMkllwBQo0YNANauTf5U1B07dgCwYcOGDEUnybr++uuB4ivFr7/+GoCrrroKKHqtaZcuXYBw1vnoo48+4Gs+//zzAIwYMQKAJ598MtmwJUU2hmj328Z7X3/99YP+7saNGxP+bNewFSpffvllpsJMoIpRRMRTKirGt99+O2PX+uabb4Dc772UcMfDL3/5ywM+74svvgAOvCtp9uzZQDg7ecsttwDQqFGjIp9/7LHHAnDbbbcBsGDBAiAca5bMq1y5MgB9+/ZNeNzWMZZkhUD16tWBcEw5V1Qxioh4SkXFaOOC2XDWWWcB6c9Ky8HZWNNxxx1X5M9thvHee+8t8TXHjRsHwPTp04FwR9Mpp5xS5POtcvRnxHfv3l3i15SSsd0s9v/xo48+CmRvXDCTVDGKiHhKRcVoM1PZ2LVgXTtsplSy5/777weguLWzts7NOq0kw3ZK2O6Kg1WOTZo0AcIekJJ5tn7R2BrSZN7H1mfT2GqSbdu2pRfcQahiFBHxlIqKcfHixUA4gzhy5EgABg8eDIQ7JJJhVcmwYcMAqFatGgCbNm1KL1hJme1wSodVjj179gTgnXfeAaBu3bpFPr9x48ZA2PtTMufss89O+PNzzz2X9DWssjfW2Xv16tWpB1YCpSIxGmseYc0q//CHPwDw6aefJn0tewPZYvFTTz0VgDlz5qQdp0Rv1apVAGzfvv2Az7NNA7fffnvWYyorbMvnMcccA4QbNGzhfjJsqMP+XZJF4Zmgr9IiIp5SVTFa80prVPvHP/4RgG7duiV9LfsqvXXr1gxFJ/nIvp6rIsw9m2T76KOPgLDZbEnY4vA6deokXGvFihWZDLFYqhhFRDylqmL0pdMIwg7def/994GweeZrr70GqJKMi6pVqx7w53bQmmSOtYKzoyus4UMybOy/Zs2aCY//5z//STO6klHFKCLiKZUVo037W7PK8uUL/hr7buuyT6mTTjoJCGede/ToAYQNDeznxpoRWLMBKZ2sUYUdcVCcZ555JhfhlCn2PkznmOOf//znANSqVSvhWraaJNtUMYqIeEplxThp0iQArrjiCiCs7mzcsHv37rRr1w6AihUrAmGbKdtiZC3SbSHwTTfdBBy4zbpkl90Da+iRyniStcL3vxn4rJJU84jMs/ecjTEmw44aGTNmTMLj1l4uVwvxVTGKiHhKZcVoxy4uXboUgAEDBiT8fObMmdxwww0AvPXWWwn/9tnxjFatSPa8++67QHiomc+2fw0aNAig8B4eyBFHHAHANddcA0C/fv2AcGzKN2HCBADGjh0LFN/QQjLH1iTabHVRbQRbtWoFhM0/bDXBwoULARg1alTW49yXKkYREU+prBht/WLTpk3TvpYddSDZ16lTJwBefvllAFq2bFnk86z669y5MxA2o93XpZdeCoRVpr/ezWdHWQwfPhyAvXv3JhO6JMF2p1jDBzv2tmvXrkDYVNjUqlWrcBWBVYq2nvjyyy8HUttnnQ5VjCIinlJZMUrpZKsG7AjTv//970U+r1y5cgA0b94cCI9ITYVVilZ9rlmzJuVrSclYG8ApU6YAYcVovQ3s53YEbt++fQvHhK3atOdG1Q5OFaOIiMflclbOOZd3U4C2zs36vI0fPx4IZy1LKgiCMtsjP9n7ar31+vTpA8DkyZMzFov15rSq9NlnnwVSP1BN9zV1tmLAqvYD7Vu3Md8LL7wQyP6OpIPdV1WMIiKeMl8xGjvA3cY4LrvssqR+X5VFSr8HwA9/+EMAhg4dCoQt8W2MsSi2++mrr74Cwi45U6dOBTK3o0X3NX3W0fv4448Hwq7pJ5xwAlCw//mhhx4CwnWL2aaKUUQkSWW+YrR9nXZ05+jRo4FwrLGkVFnEk+5rPKliFBFJUpmvGDNFlUU86b7GkypGEZEkKTGKiHiUGEVEPEqMIiIeJUYREU9OZ6VFREoDVYwiIh4lRhERjxKjiIhHiVFExKPEKCLiUWIUEfEoMYqIeJQYRUQ8SowiIh4lRhERjxKjiIhHiVFExBOrxOic2+z9s8c5NyrquCR9zrknnHOrnHMbnXNLnXNXRB2TpM8590/n3PZ93rNLoo4JYpYYgyCoav8A9YFtwNSIw5LMuAc4MgiC6sAvgZHOudYRxySZMXif9+5xUQcDMUuMnnOANcCrUQci6QuC4KMgCHbYH7//5+gIQ5IYi3Ni7AdMCtRwMjacc2Occ1uBT4FVwMyIQ5LMuMc5941z7jXnXMeog4GYNqp1zjUG/gMcEwTBf6OORzLHOVcO+CnQEfh9EAS7oo1I0uGcawt8DOwELgRGAy2DIPgiyrjiWjFeDCxUUoyfIAj2BEGwEPgRcHXU8Uh6giB4PQiCTUEQ7AiC4HHgNeAXUccV18R4CfB41EFIVpVHY4xxFAAu6iBilxidc/8HNESz0bHhnKvrnLvQOVfVOVfOOdcV6A3Mizo2SZ1zrqZzrqtzrpJzrrxz7iLgZ8CsqGMrH3UAWdAPeDYIgk1RByIZE1DwtXkcBR/my4ChQRBMjzQqSVcFYCTQFNhDwaRazyAIlkYaFTGdfBERSUfsvkqLiKRLiVFExKPEKCLiUWIUEfHkdFbaORfbmZ4gCCJfexUV3dd4Ksv3VRWjiIhHiVFExKPEKCLiUWIUEfEoMYqIeJQYRUQ8SowiIh4lRhERjxKjiIgnjv0YRaQUadq0KUOGDAHgkEMOAaBevXoA9OjRI+G5b775JgDPPvssAP/4xz8AeP/99zMakypGERFPThvVluW9l3GWqftap04dgMLq4bTTTgOgY8eOhc/ZvXs3ADNmzADg008/BWDJkiUJ13ruuecA2Lx5c8LvJUv3NfOqVasGwN133w3AJZdcQtWqVf3XBuBg+Wn79u0ATJ1acJLJpZdeWqIYtFdaRCRJeV0x9urVC4CuXbsCMG3aNAC++eabhOd99dVXANSqVQuAKlWqFHvNn/3sZwD07NkTgE8++QQIP73sWslSZVFyhx9+OABnnnkmAOeeey4AnTt3Tnjezp07AVi5cmXhY+XKlQOgUaNGJXqtd999F4BJkyYBMHr0aKDkFaTua+Y0btwYgFdeeQVIvIczZ84EYNeuXfbawMErxp/85CcA1K9fH4A///nPANx4441A+N+QTxWjiEiS8npWumnTpgBceeWVAFxxxRXA/p8my5cvB6B27doAVK5cufBn/nP9P9trWMUo2Wfjgy1atEh4/IUXXgBg4cKFAEyfXnAI4L7jh6eeeioA//znPwG45pprAHjjjTcSrtW2bVsAevfuDcBDDz0EhLOdt9xySwb+JlISNtM8ZcoUAI444gggfA8+9dRTXHzxxQDs3bs3qWvb2GSfPn0A+NWvfgUU5AAovmI8GFWMIiKevB5jHD58OABr164FYMGCBUA4TpgMm+Hs27cvEH5aPfzwwwBcf/31SV9zXxqLKrmLLroICCt8qyA///zzg/5ut27dEn73iSeeOODzraL48MMPAdi4cSMArVu3BsIxreLovqZv3LhxQPjNz7612b0bOnQo69evz8RLlZjGGEVEkpTXFaOtch8/fjwQzjilwlbId+nSBYCPP/4YgE6dOgH7z3QnS5VFfmjVqhUQji1alVK9enUATj/9dADmz59fouvpvqbPvvHZqpGJEycCcN111wGwYcOGTLxMUlQxiogkKa9npY3NHKfC1jTaTJiNb9x7771A+pWiRMNmOm1suH///gD8+Mc/BmDLli0AvPPOOwCcddZZQDTVSVnVvXt3AGrUqAGE4/oHqhRr1qwJQPny5RN+Z926ddkN1qOKUUTEk5cVo1WI9m8bY0znWscddxwQduWwXTQSnUqVKgFhtVehQoUin7dq1SoAGjRoULhbwipA+ybw0ksvATBgwAAg3PGibwS5Z9X87bffDoS7lYxfKTZo0ICrr74aoPDfNh65Y8cOoOQ7WjJFFaOIiCcvK0aTiU/7yZMnA+HY4uzZswHYunVr2teW9JxxxhlAOE541FFHHfR3bJfTPffcA4Szy353HYmOdc9p06ZNwuMvvvgiEO5gu/nmm4GCrkr2O76KFSsCMHjwYCDMCSNGjMhw1InyermOLeI1qSTKPXv2AOEg7sCBA4H0lv4URcs6Umfbt+rWrXvA511++eWcd955QPjfgr1h3nvvvXRCKJbua/JsSGTu3LlAuLlin+sCiQ0ibGneBx98kPDcc845BwgncL7++msgXJa1evXqVELUch0RkWTldcWYDts2aM0G7O/ZrFkzIGxwmimqLHLDvlrZIP2wYcMA+Ne//gXABRdcABx8q19J6b6mzirFefPmAWEluWnTJgCefPJJoGDpXHHt/qwtoE2e+tdetGhRSrGpYhQRSVJeT76kw5bpWKVoy3QyXSlKyVmbMZtASaVxgC3TsOYftkxnzpw5ACxevBiA888/H4AvvvgijYglHdY+zr6l2bKdbdu2ASVrCm3vX3+h94oVKzIbrEcVo4iIJ7YVY/v27YFwBswOR5Lcs9lmq+rscKtMtJqybwA2W22bAWwZjx2XsHTp0rRfS1JTknZyPvvG17Bhw4TH//3vfwOwbNmy9AM7AFWMIiKe2FaM/hijzW5J7v3iF78AwqMLrOVbJtnYoh3QbmOPY8aMAcIthDa+Jfnt8ccfB9jvWNVcbeVVxSgi4ollxdi6devClfE2xijRy0XLL5vpvOOOO4CCg5YA2rVrB4S7MSQ/WUuyU045BQi/8U2YMAGAxx57LCdxqGIUEfHEsmKEgx/ULbljbcNsn7rte81mBWmrEGzW2vbcqmLMT7ZT7cEHHwTCb3q2S2bkyJFA5nY0HYwqRhERT2wrRvvE0Rhj9F599VWAwiazXbt2BeCZZ54Bkj9kvSRsh4x1Xzn11FMz/hqSHuuqNHjw4MIGtPZNzyrDm266CSjZLplMUsUoIuKJbcVonzw2xqQ90tGxpsD26T9p0iQg3EN79913A2Eb+0ywCsT2Z991110Zu7aUTNu2bQE4/PDDgXAN4q9//WsAhgwZAsAJJ5yw3+8+9NBDAPzpT3/KepxFUcUoIuKJZcV45ZVXFo4t3nrrrYCOMsgH/jET1kW9Z8+eQNhb0cYkN2/eXOJrW9XhH6r0wAMPANFVHmVZ/fr1gfAbgu06ss78+64c+eyzz4BwveL999+fsziLoopRRMQTyw7eq1evLjx+0Q7uzjZ1ek5ey5YtARg6dCgQjknZOsdZs2YBMHXqVKCg4rDjUm0nS5cuXYCwC4t1chk1ahQAY8eOTSW0QrqvqbP7+9prrwHhcbn2jcHO6Zk2bVphpZjtPotGHbxFRJIUq4qxTp06AKxZs6ZwbZx/2He2qLJIX5UqVYBw9trO9WjevDlQME7cuHFjIByHtC7RVpVYz8dMHciu+xpPqhhFRJIUq4rRZrtWr15d2PPPqo1sU2URT7qv8aSKUUQkSbGqGKOkyiKedF/jSRWjiEiScloxioiUBqoYRUQ8SowiIh4lRhERjxKjiIhHiVFExKPEKCLiUWIUEfEoMYqIeJQYRUQ8SowiIh4lRhERjxKjiIhHiVFExKPEKCLiUWIUEfEoMYqIeJQYRUQ8SowiIh4lRhERjxKjiIhHiVFExKPEKCLiUWIUEfH8P5C0HNlIzyXoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(42000, 28, 28)\n",
    "print(X_train.shape)\n",
    "for i in range(0,9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.subplots_adjust(hspace = 0.5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y_train[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "y_train= keras.utils.to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "print(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/luishengjie/anaconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/luishengjie/anaconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# CNN Architecture\n",
    "model = keras.Sequential([keras.layers.Conv2D(32, kernel_size=(5, 5), activation ='relu', input_shape=(28,28,1)),\n",
    "                          keras.layers.Conv2D(32, kernel_size=(5, 5), activation ='relu'),\n",
    "                          keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                          keras.layers.Dropout(0.25),\n",
    "                          \n",
    "                          keras.layers.Conv2D(64, kernel_size=(3, 3), activation ='relu'),\n",
    "                          keras.layers.Conv2D(64, kernel_size=(3, 3), activation ='relu'),\n",
    "                          keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "                          keras.layers.Dropout(0.25),\n",
    "                          \n",
    "                          keras.layers.Flatten(), \n",
    "                          keras.layers.Dense(256, activation='relu'),\n",
    "                          keras.layers.Dropout(0.2),\n",
    "                          keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation\n",
    "# Integrate generator with kerasâ€™ using ImageDataGenerator.flow()\n",
    "generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
    "\n",
    "batches = generator.flow(X_train, y_train, batch_size=64)\n",
    "val_batches = generator.flow(X_val, y_val, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/luishengjie/anaconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0633 - acc: 0.9811\n",
      "525/525 [==============================] - 74s 141ms/step - loss: 0.2579 - acc: 0.9164 - val_loss: 0.0633 - val_acc: 0.9811\n",
      "Epoch 2/30\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0449 - acc: 0.9854\n",
      "525/525 [==============================] - 77s 147ms/step - loss: 0.0760 - acc: 0.9770 - val_loss: 0.0449 - val_acc: 0.9854\n",
      "Epoch 3/30\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 0.0581 - acc: 0.9827\n",
      "525/525 [==============================] - 77s 146ms/step - loss: 0.0562 - acc: 0.9828 - val_loss: 0.0581 - val_acc: 0.9827\n",
      "Epoch 4/30\n",
      "132/132 [==============================] - 6s 48ms/step - loss: 0.0317 - acc: 0.9896\n",
      "525/525 [==============================] - 73s 139ms/step - loss: 0.0470 - acc: 0.9852 - val_loss: 0.0317 - val_acc: 0.9896\n",
      "Epoch 5/30\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 0.0320 - acc: 0.9899\n",
      "525/525 [==============================] - 76s 144ms/step - loss: 0.0423 - acc: 0.9870 - val_loss: 0.0320 - val_acc: 0.9899\n",
      "Epoch 6/30\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0418 - acc: 0.9885\n",
      "525/525 [==============================] - 76s 146ms/step - loss: 0.0361 - acc: 0.9893 - val_loss: 0.0418 - val_acc: 0.9885\n",
      "Epoch 7/30\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0246 - acc: 0.9926\n",
      "525/525 [==============================] - 76s 146ms/step - loss: 0.0341 - acc: 0.9896 - val_loss: 0.0246 - val_acc: 0.9926\n",
      "Epoch 8/30\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0289 - acc: 0.9919\n",
      "525/525 [==============================] - 79s 151ms/step - loss: 0.0306 - acc: 0.9906 - val_loss: 0.0289 - val_acc: 0.9919\n",
      "Epoch 9/30\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 0.0313 - acc: 0.9918\n",
      "525/525 [==============================] - 78s 148ms/step - loss: 0.0301 - acc: 0.9912 - val_loss: 0.0313 - val_acc: 0.9918\n",
      "Epoch 10/30\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0234 - acc: 0.9927\n",
      "525/525 [==============================] - 76s 144ms/step - loss: 0.0280 - acc: 0.9918 - val_loss: 0.0234 - val_acc: 0.9927\n",
      "Epoch 11/30\n",
      "132/132 [==============================] - 7s 52ms/step - loss: 0.0231 - acc: 0.9931\n",
      "525/525 [==============================] - 79s 151ms/step - loss: 0.0269 - acc: 0.9918 - val_loss: 0.0231 - val_acc: 0.9931\n",
      "Epoch 12/30\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0252 - acc: 0.9940\n",
      "525/525 [==============================] - 76s 144ms/step - loss: 0.0257 - acc: 0.9925 - val_loss: 0.0252 - val_acc: 0.9940\n",
      "Epoch 13/30\n",
      "132/132 [==============================] - 7s 53ms/step - loss: 0.0332 - acc: 0.9921\n",
      "525/525 [==============================] - 78s 149ms/step - loss: 0.0245 - acc: 0.9929 - val_loss: 0.0332 - val_acc: 0.9921\n",
      "Epoch 14/30\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 0.0251 - acc: 0.9926\n",
      "525/525 [==============================] - 79s 150ms/step - loss: 0.0254 - acc: 0.9924 - val_loss: 0.0251 - val_acc: 0.9926\n",
      "Epoch 15/30\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 0.0253 - acc: 0.9924\n",
      "525/525 [==============================] - 78s 148ms/step - loss: 0.0247 - acc: 0.9926 - val_loss: 0.0253 - val_acc: 0.9924\n",
      "Epoch 16/30\n",
      "132/132 [==============================] - 8s 58ms/step - loss: 0.0390 - acc: 0.9908\n",
      "525/525 [==============================] - 76s 145ms/step - loss: 0.0233 - acc: 0.9930 - val_loss: 0.0390 - val_acc: 0.9908\n",
      "Epoch 17/30\n",
      "132/132 [==============================] - 7s 55ms/step - loss: 0.0294 - acc: 0.9920\n",
      "525/525 [==============================] - 78s 149ms/step - loss: 0.0239 - acc: 0.9937 - val_loss: 0.0294 - val_acc: 0.9920\n",
      "Epoch 18/30\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0364 - acc: 0.9932: 0s - loss: 0.0353 \n",
      "525/525 [==============================] - 78s 149ms/step - loss: 0.0239 - acc: 0.9937 - val_loss: 0.0364 - val_acc: 0.9932\n",
      "Epoch 19/30\n",
      "132/132 [==============================] - 8s 57ms/step - loss: 0.0304 - acc: 0.9915\n",
      "525/525 [==============================] - 80s 152ms/step - loss: 0.0248 - acc: 0.9932 - val_loss: 0.0304 - val_acc: 0.9915\n",
      "Epoch 20/30\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 0.0281 - acc: 0.9914\n",
      "525/525 [==============================] - 78s 148ms/step - loss: 0.0248 - acc: 0.9935 - val_loss: 0.0281 - val_acc: 0.9914\n",
      "Epoch 21/30\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0417 - acc: 0.9912\n",
      "525/525 [==============================] - 77s 146ms/step - loss: 0.0227 - acc: 0.9936 - val_loss: 0.0417 - val_acc: 0.9912\n",
      "Epoch 22/30\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 0.0278 - acc: 0.9927\n",
      "525/525 [==============================] - 73s 139ms/step - loss: 0.0236 - acc: 0.9938 - val_loss: 0.0278 - val_acc: 0.9927\n",
      "Epoch 23/30\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0326 - acc: 0.9914\n",
      "525/525 [==============================] - 73s 139ms/step - loss: 0.0246 - acc: 0.9942 - val_loss: 0.0326 - val_acc: 0.9914\n",
      "Epoch 24/30\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0289 - acc: 0.9932\n",
      "525/525 [==============================] - 76s 144ms/step - loss: 0.0249 - acc: 0.9943 - val_loss: 0.0289 - val_acc: 0.9932\n",
      "Epoch 25/30\n",
      "132/132 [==============================] - 7s 51ms/step - loss: 0.0511 - acc: 0.9896\n",
      "525/525 [==============================] - 74s 141ms/step - loss: 0.0243 - acc: 0.9939 - val_loss: 0.0511 - val_acc: 0.9896\n",
      "Epoch 26/30\n",
      "132/132 [==============================] - 6s 49ms/step - loss: 0.0434 - acc: 0.9908\n",
      "525/525 [==============================] - 73s 140ms/step - loss: 0.0238 - acc: 0.9946 - val_loss: 0.0434 - val_acc: 0.9908\n",
      "Epoch 27/30\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0491 - acc: 0.9933\n",
      "525/525 [==============================] - 73s 139ms/step - loss: 0.0225 - acc: 0.9944 - val_loss: 0.0491 - val_acc: 0.9933\n",
      "Epoch 28/30\n",
      "132/132 [==============================] - 7s 54ms/step - loss: 0.0416 - acc: 0.9936\n",
      "525/525 [==============================] - 76s 145ms/step - loss: 0.0279 - acc: 0.9937 - val_loss: 0.0416 - val_acc: 0.9936\n",
      "Epoch 29/30\n",
      "132/132 [==============================] - 7s 50ms/step - loss: 0.0383 - acc: 0.9932\n",
      "525/525 [==============================] - 74s 142ms/step - loss: 0.0245 - acc: 0.9942 - val_loss: 0.0383 - val_acc: 0.9932\n",
      "Epoch 30/30\n",
      "132/132 [==============================] - 7s 56ms/step - loss: 0.0386 - acc: 0.9930\n",
      "525/525 [==============================] - 74s 141ms/step - loss: 0.0249 - acc: 0.9942 - val_loss: 0.0386 - val_acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=30, validation_data=val_batches, validation_steps=val_batches.n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "\n",
    "submissions.to_csv(\"submission.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
